{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c8ebeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os # for interacting with the operating system\n",
    "import numpy as np # for linear algebra operations\n",
    "import pandas as pd # for data processing and reading/writing CSV files\n",
    "import matplotlib.pyplot as plt # for plotting data\n",
    "import seaborn as sns # for creating beautiful plots\n",
    "import librosa # a library for analyzing audio and music\n",
    "import librosa.display # for displaying audio data\n",
    "from IPython.display import Audio # for playing audio files\n",
    "\n",
    "# Importing necessary modules from scikit-learn library\n",
    "# StandardScaler is used for feature scaling\n",
    "# OneHotEncoder is used for one-hot encoding categorical variables\n",
    "# confusion_matrix and classification_report are used for evaluating the performance of a classifier\n",
    "# train_test_split is used for splitting the data into training and testing sets\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, AveragePooling1D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, AveragePooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7919c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(in_shape):\n",
    "    # Define input layer\n",
    "    input_layer = Input(shape=(in_shape, 1))\n",
    "    \n",
    "    # Add a 1D convolution layer with 256 filters, kernel size 6, stride 1, 'same' padding, ReLU activation\n",
    "    x = Conv1D(256, kernel_size=6, strides=1, padding='same', activation='relu')(input_layer)\n",
    "    # Add an average pooling layer with pool size 4, stride 2, and 'same' padding\n",
    "    x = AveragePooling1D(pool_size=4, strides=2, padding='same')(x)\n",
    "\n",
    "    # Add another 1D convolution layer with 128 filters, kernel size 6, stride 1, 'same' padding, and ReLU activation\n",
    "    x = Conv1D(128, kernel_size=6, strides=1, padding='same', activation='relu')(x)\n",
    "    # Add another average pooling layer with pool size 4, stride 2, and 'same' padding\n",
    "    x = AveragePooling1D(pool_size=4, strides=2, padding='same')(x)\n",
    "\n",
    "    # Add a third 1D convolution layer with 128 filters, kernel size 6, stride 1, 'same' padding, and ReLU activation\n",
    "    x = Conv1D(128, kernel_size=6, strides=1, padding='same', activation='relu')(x)\n",
    "    # Add another average pooling layer with pool size 4, stride 2, and 'same' padding\n",
    "    x = AveragePooling1D(pool_size=4, strides=2, padding='same')(x)\n",
    "    # Add a dropout layer with rate 0.2 to reduce overfitting\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Add a fourth 1D convolution layer with 64 filters, kernel size 6, stride 1, 'same' padding, and ReLU activation\n",
    "    x = Conv1D(64, kernel_size=6, strides=1, padding='same', activation='relu')(x)\n",
    "    # Add a max pooling layer with pool size 4, stride 2, and 'same' padding\n",
    "    x = MaxPooling1D(pool_size=4, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Flatten the output from the previous layer to prepare for fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    # Add a dense layer with 32 units and ReLU activation\n",
    "    x = Dense(units=32, activation='relu')(x)\n",
    "    # Add another dropout layer with rate 0.3 to reduce overfitting\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Add a final dense layer with 8 units and softmax activation\n",
    "    output_layer = Dense(units=8, activation='softmax')(x)\n",
    "    \n",
    "    # Define the model with input and output layers\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    # Compile the model using the Adam optimizer, categorical crossentropy loss, and accuracy metrics\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4b5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to build and summarize a model\n",
    "def build_summary_of_model(model_dimensions, train_features, validation_features, validation_labels):\n",
    "    \n",
    "    # Create a model with the specified number of dimensions\n",
    "    model = create_model(model_dimensions)\n",
    "    # Display a summary of the model's architecture\n",
    "    model.summary()\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    score = model.evaluate(validation_features, validation_labels, verbose = 1)\n",
    "    # Calculate the accuracy of the model on the validation set\n",
    "    accuracy = 100*score[1]\n",
    "    \n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f5a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
